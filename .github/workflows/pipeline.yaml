name: CdkPipeline

on:
  push:
    branches:
      - 'dev'
      - 'prod'

env:
  PIPELINE_USER_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  PIPELINE_USER_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  PIPELINE_EXECUTION_ROLE: arn:aws:iam::471112837636:role/cdk-pipeline-deployment-role
  TESTING_REGION: us-east-1
  PROD_REGION: us-east-1
  AWS_ACCOUNT_ID: 471112837636

jobs:
  # ========== DEV ENVIRONMENT ==========
  test-dev:
    if: github.ref == 'refs/heads/dev'
    runs-on: ubuntu-latest
    env:
      STAGE: dev
      TEST_DATA_BUCKET: densenet-test-data-dev
      MODEL_REPOSITORY: densenet121-model-dev
      AWS_REGION: us-east-1
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install test dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements-test.txt
          pip install docker boto3 requests Pillow numpy onnxruntime
          
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ env.PIPELINE_USER_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.PIPELINE_USER_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ env.PIPELINE_EXECUTION_ROLE }}
          role-session-name: testing-session-dev
          role-duration-seconds: 3600
          role-skip-session-tagging: true

      - name: Setup test data bucket
        run: |
          python -c "
          import boto3
          import time
          s3 = boto3.client('s3')
          bucket_name = '${{ env.TEST_DATA_BUCKET }}'
          
          try:
              s3.head_bucket(Bucket=bucket_name)
              print(f'Bucket {bucket_name} ya existe')
          except:
              if '${{ env.AWS_REGION }}' == 'us-east-1':
                  s3.create_bucket(Bucket=bucket_name)
              else:
                  s3.create_bucket(
                      Bucket=bucket_name,
                      CreateBucketConfiguration={'LocationConstraint': '${{ env.AWS_REGION }}'}
                  )
              print(f'Bucket {bucket_name} creado')
              time.sleep(5)
          "

      - name: Generate and upload test data
        run: |
          python scripts/generate_test_data.py

      - name: Download model from ECR for tests
        run: |
          sudo mkdir -p /tmp
          sudo chmod 777 /tmp
          echo "Descargando modelo desde ECR para tests..."
          python scripts/download_model.py
          if [ ! -f "/tmp/densenet121_Opset17.onnx" ]; then
            echo "Error: El modelo no se descargó correctamente"
            exit 1
          fi
          echo "Modelo descargado exitosamente para tests"
          ls -l /tmp/densenet121_Opset17.onnx

      - name: Run tests
        run: |
          if [ ! -f "/tmp/densenet121_Opset17.onnx" ]; then
            echo "Error: El modelo no existe en /tmp"
            ls -la /tmp
            exit 1
          fi
          pytest tests/test_model.py -v

  deploy-dev:
    needs: [test-dev]
    if: github.ref == 'refs/heads/dev'
    runs-on: ubuntu-latest
    env:
      STAGE: dev
      MODEL_REPOSITORY: densenet121-model-dev
      STACK_NAME: densenet-fargate-dev
      AWS_REGION: us-east-1
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Set up Node
        uses: actions/setup-node@v3
        with:
          node-version: '20'
          
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ env.PIPELINE_USER_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.PIPELINE_USER_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ env.PIPELINE_EXECUTION_ROLE }}
          role-session-name: deployment-session-dev
          role-duration-seconds: 3600
          role-skip-session-tagging: true
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          npm install -g aws-cdk
          
      - name: Build and push Docker image
        run: |
          # Login to ECR
          aws ecr get-login-password --region ${{ env.AWS_REGION }} | docker login --username AWS --password-stdin ${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com
          
          # Create ECR repository if it doesn't exist
          aws ecr describe-repositories --repository-names app-${{ env.STAGE }} || \
          aws ecr create-repository --repository-name app-${{ env.STAGE }}
          
          # Build Docker image (modelo se descarga en runtime, no en build time)
          docker build -t app:latest \
            --build-arg AWS_REGION=${{ env.AWS_REGION }} \
            --build-arg STAGE=${{ env.STAGE }} \
            --build-arg MODEL_REPOSITORY=${{ env.MODEL_REPOSITORY }} \
            --build-arg AWS_ACCESS_KEY_ID=${{ env.PIPELINE_USER_ACCESS_KEY_ID }} \
            --build-arg AWS_SECRET_ACCESS_KEY=${{ env.PIPELINE_USER_SECRET_ACCESS_KEY }} \
            --build-arg AWS_ACCOUNT_ID=${{ env.AWS_ACCOUNT_ID }} \
            .
          
          # Tag and push to ECR
          docker tag app:latest ${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/app-${{ env.STAGE }}:latest
          docker push ${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/app-${{ env.STAGE }}:latest
          
      - name: Deploy with CDK
        run: |
          cdk deploy --app="python3 ${PWD}/app.py" \
            --require-approval=never \
            -c stage=${{ env.STAGE }} \
            -c region=${{ env.AWS_REGION }} \
            ${{ env.STACK_NAME }}

  # ========== PROD ENVIRONMENT ==========
  test-prod:
    if: github.ref == 'refs/heads/prod'
    runs-on: ubuntu-latest
    env:
      STAGE: prod
      TEST_DATA_BUCKET: densenet-test-data-prod
      MODEL_REPOSITORY: densenet121-model-prod
      AWS_REGION: us-east-1
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install test dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements-test.txt
          pip install docker boto3 requests Pillow numpy onnxruntime
          
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ env.PIPELINE_USER_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.PIPELINE_USER_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ env.PIPELINE_EXECUTION_ROLE }}
          role-session-name: testing-session-prod
          role-duration-seconds: 3600
          role-skip-session-tagging: true

      - name: Setup test data bucket
        run: |
          python -c "
          import boto3
          import time
          s3 = boto3.client('s3')
          bucket_name = '${{ env.TEST_DATA_BUCKET }}'
          
          try:
              s3.head_bucket(Bucket=bucket_name)
              print(f'Bucket {bucket_name} ya existe')
          except:
              if '${{ env.AWS_REGION }}' == 'us-east-1':
                  s3.create_bucket(Bucket=bucket_name)
              else:
                  s3.create_bucket(
                      Bucket=bucket_name,
                      CreateBucketConfiguration={'LocationConstraint': '${{ env.AWS_REGION }}'}
                  )
              print(f'Bucket {bucket_name} creado')
              time.sleep(5)
          "

      - name: Generate and upload test data
        run: |
          python scripts/generate_test_data.py

      - name: Download model from ECR for tests
        run: |
          sudo mkdir -p /tmp
          sudo chmod 777 /tmp
          echo "Descargando modelo desde ECR para tests..."
          python scripts/download_model.py
          if [ ! -f "/tmp/densenet121_Opset17.onnx" ]; then
            echo "Error: El modelo no se descargó correctamente"
            exit 1
          fi
          echo "Modelo descargado exitosamente para tests"
          ls -l /tmp/densenet121_Opset17.onnx

      - name: Run tests
        run: |
          if [ ! -f "/tmp/densenet121_Opset17.onnx" ]; then
            echo "Error: El modelo no existe en /tmp"
            ls -la /tmp
            exit 1
          fi
          pytest tests/test_model.py -v

  deploy-prod:
    needs: [test-prod]
    if: github.ref == 'refs/heads/prod'
    runs-on: ubuntu-latest
    env:
      STAGE: prod
      MODEL_REPOSITORY: densenet121-model-prod
      STACK_NAME: densenet-fargate-prod
      AWS_REGION: us-east-1
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Set up Node
        uses: actions/setup-node@v3
        with:
          node-version: '20'
          
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ env.PIPELINE_USER_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.PIPELINE_USER_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ env.PIPELINE_EXECUTION_ROLE }}
          role-session-name: deployment-session-prod
          role-duration-seconds: 3600
          role-skip-session-tagging: true
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          npm install -g aws-cdk
          
      - name: Build and push Docker image
        run: |
          # Login to ECR
          aws ecr get-login-password --region ${{ env.AWS_REGION }} | docker login --username AWS --password-stdin ${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com
          
          # Create ECR repository if it doesn't exist
          aws ecr describe-repositories --repository-names app-${{ env.STAGE }} || \
          aws ecr create-repository --repository-name app-${{ env.STAGE }}
          
          # Build Docker image (modelo se descarga en runtime, no en build time)
          docker build -t app:latest \
            --build-arg AWS_REGION=${{ env.AWS_REGION }} \
            --build-arg STAGE=${{ env.STAGE }} \
            --build-arg MODEL_REPOSITORY=${{ env.MODEL_REPOSITORY }} \
            --build-arg AWS_ACCESS_KEY_ID=${{ env.PIPELINE_USER_ACCESS_KEY_ID }} \
            --build-arg AWS_SECRET_ACCESS_KEY=${{ env.PIPELINE_USER_SECRET_ACCESS_KEY }} \
            --build-arg AWS_ACCOUNT_ID=${{ env.AWS_ACCOUNT_ID }} \
            .
          
          # Tag and push to ECR
          docker tag app:latest ${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/app-${{ env.STAGE }}:latest
          docker push ${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/app-${{ env.STAGE }}:latest
          
      - name: Deploy with CDK
        run: |
          cdk deploy --app="python3 ${PWD}/app.py" \
            --require-approval=never \
            -c stage=${{ env.STAGE }} \
            -c region=${{ env.AWS_REGION }} \
            ${{ env.STACK_NAME }}